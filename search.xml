<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Zabbix3.4升级4.2线上操作方案]]></title>
    <url>%2F2019%2F06%2F03%2FZabbix3.4%E5%8D%87%E7%BA%A74.2%E7%BA%BF%E4%B8%8A%E6%93%8D%E4%BD%9C%E6%96%B9%E6%A1%88%2F</url>
    <content type="text"><![CDATA[场景说明 业务场景：生产环境为引入zabbix 新功能，有升级需求。 风险zabbix_server版本升级，需要暂停应用。该时间段的监控数据不会采集。 基础流程： ️备份数zabbix_server、zabbix_proxy数据库 ️升级zabbix_server、zabbix_proxy 应用 升级前端php文件 前端页面设置 测试环境 系统环境：centos 7.4 备份工具：xtrabackup mysqldump zabbix版本：3.4.14(升级前)—–&gt;4.2.1(升级后) zabbix_server升级文件备份数据库备份工具介绍 Mysql最常用的三种备份工具：（1）mysqldump：通常为小数据情况下的备份innodb： 热备，温备MyISAM, Aria: 温备单线程备份恢复比较慢（2）Xtrabackup（通常用innobackupex工具）：备份mysql大数据InnoDB热备，增量备份；MyISAM温备，不支持增量，只有完全备份属于物理备份，速度快；（3）lvm-snapshot：接近于热备的工具：因为要先请求全局锁，而后创建快照，并在创建快照完成后释放全局锁；使用cp、tar等工具进行物理备份；备份和恢复速度较快；很难实现增量备份，并且请求全局需要等待一段时间，在繁忙的服务器上尤其如此 因线上zabbix_server数据库大小高达800G，根据以上数据库相关备份工具特点，本次备份采用xtrabackup工具备份参考文档：innobackupex 备份及恢复数据库 server库备份 查看MySQL数据存放位置及大小 12345$ grep &apos;datadir&apos; /etc/my.cnfdatadir=/var/lib/mysql$ du -sh /var/lib/mysql1.5G /var/lib/mysql 停掉zabbix server 1$ systemctl stop zabbix_server 对zabbix_server 所在MySQL 全量备份 1$ innobackupex --defaults-file=/etc/my.cnf --user=root --password=&apos;Asp@aspire+888&apos; --host=localhost /root/backup/xtrabackup/ server配置文件备份 查看升级前zabbix_server 版本信息 1234567891011$ /opt/aspire/product/zabbixsvr/sbin/zabbix_server -Vzabbix_server (Zabbix) 3.4.14Revision 92832 18 April 2019, compilation time: Jun 5 2019 14:47:01$ mysql -uroot -p&apos;Asp@aspire+888&apos;mysql&gt; use zabbixsvr;mysql&gt; select * from dbversion;+-----------+----------+| mandatory | optional |+-----------+----------+| 3040000 | 30470000 |+-----------+----------+ 备份zabbix_server 1$ mv /opt/aspire/product/web/website/zabbixsvr /opt/aspire/product/web/website/zabbixsvr3.4 备份php页面文件 1$ mv /opt/aspire/product/web/website/zabbix /opt/aspire/product/web/website/zabbix3.4 备份启动脚本 1$ cp /etc/init.d/zabbix_server /etc/init.d/zabbix_server3.4 zabbix_server 升级 编译安装zabbix_server 4.2 123$ ./configure --prefix=/opt/aspire/product/zabbixsvr --with-mysql=/usr/bin/mysql_config --enable-server --enable-proxy --enable-agent --enable-ipv6 --with-libxml-dir=/opt/aspire/product/web/libxml2/ --with-unixODBC --with-net-snmp --with-SSH2 --with-openIPMI --with-libcurl$ make$ make install 修改zabbix_server 配置文件 123456789101112131415$ grep -v &quot;^#&quot; /opt/aspire/product/zabbixsvr3.4/etc/zabbix_server.conf |grep -v &quot;^$&quot; LogFile=/tmp/zabbix_server.logDBHost=localhostDBName=zabbixsvrDBUser=zabbixDBPassword=Asp@zabbix_asp_2019DBSocket=/tmp/mysql.sockStartPollers=50CacheSize=128MHistoryCacheSize=256MTrendCacheSize=128MValueCacheSize=128MTimeout=4LogSlowQueries=3000 加载启动脚本 1systemctl reload zabbix_server.service 升级zabbix_server，观察日志输出 123systemctl start mysqld.service systemctl start zabbix_server.service tail -f /tmp/zabbix_server.log 拷贝PHP文件 12$ cp -rf frontends/php/ /opt/aspire/product/web/apache/website/ $ mv /opt/aspire/product/web/apache/website/php /opt/aspire/product/web/apache/website/zabbix web页面依次设置即可 注意：如果升级过程中数据同步失败或出现无法解决的问题需要回滚版本，使用如下操作回退并恢复数据 停止mysql服务12systemctl stop mysqld.service mv /var/lib/mysql/ /var/lib/mysql_bak &amp;&amp; mkdir -p /var/lib/mysql 执行恢复操作 12345//--apply-log选项的命令是准备在一个备份上启动mysql服务$ innobackupex --defaults-file=/etc/my.cnf --user=root --passwod=&apos;Asp@aspire+888&apos; --apply-log /root/backup/xtrabackup/2019-06-06_10-47-30//--copy-back 选项的命令从备份目录拷贝数据,索引,日志到my.cnf文件里规定的初始位置$ innobackupex --defaults-file=/etc/my.cnf --user=root --passwod=&apos;Asp@aspire+888&apos; --copy-back /root/backup/xtrabackup/2019-06-06_10-47-30 授权目录，启动服务 12$ chown -R mysql:mysql /var/lib/mysql$ systemctl start mysqld.service 恢复zabbix配置文件及php文件 1省略 zabbix_proxy 升级文件备份说明：proxy库文件不大，可使用mysqldump方式备份备份proxy文件 停掉zabbix proxy 1$ systemctl stop zabbix_proxy 备份zabbix_proxy 1$ mv /opt/aspire/product/zabbixpxy /opt/aspire/product/zabbixpxy3.4 备份启动脚本 1$ cp /etc/init.d/zabbix_proxy /etc/init.d/zabbix_proxy2.2.7 备份proxy 数据库1$ mysqldump -uzabbix –pzabbix_asp_2018 --skip-lock-tables zabbix_proxy &gt; zabbix_proxybak.sql zabbix_proxy 升级 编译安装 zabbix_proxy 4.2MySQL 编译参数： 123$ ./configure --prefix=/opt/aspire/product/zabbixpxy --with-mysql=/usr/bin/mysql_config --enable-proxy --enable-agent --enable-ipv6 --with-libxml-dir=/opt/aspire/product/web/libxml2/ --with-unixODBC --with-net-snmp --with-ssh2 --with-openIPMI --with-libcurl=/usr/local/src/bin/curl-config$ make$ make install 修改zabbix_proxy 配置文件 1234567891011121314151617$ grep -v &quot;^#&quot; /opt/aspire/product/zabbixpxy/etc/zabbix_proxy.conf |grep -v &quot;^$&quot;Server=127.0.0.1Hostname=Zabbix proxyListenPort=10061LogFile=/tmp/zabbix_proxy.logDBHost=localhostDBName=zabbixpxyDBUser=zabbixDBPassword=Asp@zabbix_asp_2019DBSocket=/tmp/mysql.sockStartPollers=50CacheSize=128MHistoryCacheSize=128MTimeout=4FpingLocation=/usr/local/sbin/fpingLogSlowQueries=3000 加载启动脚本 1systemctl reload zabbix_proxy.service 升级zabbix_proxy 123systemctl start mysqld.service systemctl start zabbix_proxy.service tail -f /tmp/zabbix_proxy.log 注意：如果升级过程中数据同步失败或出现无法解决的问题需要回滚版本，使用如下操作回退并恢复数据123456789新建zabbix_proxy库并授权$ mysql -uroot -pmysql&gt; create database zabbix_proxy character set utf8 collate utf8_bin;mysql&gt; grant all privileges on zabbix_proxy.* to zabbix@&apos;localhost&apos; identified by &apos;zabbix_asp_2018&apos;;mysql&gt; flush privileges;mysql&gt; quit;导入备份的zabbix_proxy库文件$ mysql -uzabbix -pzabbix zabbix_proxy &lt; zabbix_proxybak.sql]]></content>
      <categories>
        <category>Zabbix</category>
      </categories>
      <tags>
        <tag>zabbix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Zabbix + ElasticSearch + Kibana 实践]]></title>
    <url>%2F2019%2F05%2F25%2FZabbix%2BElasticSearch%2BKibana%20%E5%AE%9E%E8%B7%B5%2F</url>
    <content type="text"><![CDATA[categories: ZabbixZabbix + ElasticSearch + Kibana 安装配置介绍zabbix 4.2 新版本特性： 支持时序数据库（TimescaleDB） 支持Prometheus数据采集（Built-in） 高效高频监控 采集的数据验证和错误处理 使用JavaScript预处理数据 从UI测试预处理规则 每秒处理百万级别指标 简单的低级别自动发现（low level discovery） 简化的tag管理 更灵活的自动注册 控制自动发现的主机名 从Web UI测试媒介类型 elasticSearch 介绍 Elasticsearch 是一个分布式、RESTful 风格的搜索和数据分析引擎，它的目的是通过简单的RESTful API来隐藏Lucene的复杂性，从而让全文搜索变得简单。 Kibana 介绍 Kibana是一个开源的分析和可视化平台，设计用于和Elasticsearch一起工作。可以用用Kibana来搜索，查看，并和存储在Elasticsearch索引中的数据进行交互。可以轻松地执行高级数据分析，并且以各种图标、表格和地图的形式可视化数据。 zabbix+elasticsearch官网介绍 &emsp;zabbix支持Elasticsearch是实验性！配置步骤适用于以下Elasticsearch版本： 5.0.x - &gt; 6.1.x ,如果使用早期或更高版本的Elasticsearch，某些功能可能无法按预期工作。&emsp;Zabbix最近开始支持通过使用Elasticsearch而不是数据库来存储历史数据。 现在，用户可以在兼容数据库和Elasticsearch之间选择历史数据的存储位置。 环境说明本次测试系统环境 操作系统：CentOS 7.5 CPU：8核 内存：32G 硬盘：500G 本次相关应用版本 Zabbix: 4.2.1 LTS Elasticsearch：6.1.4 Kibana：6.1.4 Httpd：2.4.35 PHP：7.2.11 Mysql：5.7.24 Apache + PHP + Mysql + Zabbix源码安装apache安装省略 PHP安装省略 mysql安装省略 zabbix安装zabbix4.2编译安装123456789101112131415161718创建文件夹mkdir -p /opr/aspire/product/packagemkdir -p /opt/aspire/product/zabbix 新建zabbix用户useradd zabbixpasswd zabbix 解压源码包tar zxvf zabbix-4.2.1.tar.gz -C /opt/aspire/product/package 目录授权chown -R zabbix.zabbix /opt/aspire/product/zabbix 编译安装cd /opt/aspire/product/zabbix./configure --prefix=/opt/aspire/product/zabbix --enable-server --enable-agent --with-mysql --with-net-snmp --with-libcurl --with-libxml2 --with-openIPMI --with-unixODBCmake &amp;&amp; make install 创建数据库导入数据1234567891011新建zabbix数据库&gt; create database zabbix character set utf-8 collate utf-8_bin&gt; grant all privileges on zabbix.* to zabbix_server@&quot;localhost&quot; identified by &quot;zabbix_password&quot;&gt; flush privileges&gt; exit 导入zabbix数据cd /opt/aspire/product/package/zabbix-4.2.1/database/mysqlmysql -uzabbix -pzabbix_password &lt; schema.sqlmysql -uzabbix -pzabbix_password zabbix &lt; images.sqlmysql -uzabbix -pzabbix_password zabbix &lt; data.sql 修改php参数12345678$ vi /etc/php.ini date.timezone= Asia/Shanghaimax_execution_time = 300post_max_size = 32Mmemory_limit = 128Mmbstring.func_overload = 1max_input_time = 300 拷贝php文件到web目录12345拷贝php文件cp -r /opt/aspire/product/package/zabbix-4.2.1/frontends/php/ /opt/aspire/product/web/website/ 目录授权chown -R zabbix.zabbix /opt/aspire/product/web/website/zabbix 修改zabbix_server配置文件12345678910111213创建日志目录授权mkdir -p /opt/aspire/product/zabbix/logschown zabbix.zabbix /opt/aspire/product/zabbix/logs 修改zabbix_server.conf$ vi /opt/aspire/product/zabbix/etc/zabbix_server.conf LogFile=/opt/aspire/product/zabbix/logs/zabbix_server.logDBName=zabbixDBUser=zabbixDBPassword=zabbix2018Timeout=4LogSlowQueries=3000 zabbix服务自启动1234567891011121314拷贝启动脚本cd /opt/aspire/product/package/zabbix-4.2.1cp misc/init.d/fedora/core/zabbix_server /etc/init.d/ 编辑启动文件vi /etc/init.d/zabbix_server BASEDIR=/opt/aspire/product/zabbixCONFFILE=$BASEDIR/etc/zabbix_server.confaction $&quot;Starting $BINARY_NAME: &quot; $FULLPATH -c $CONFFILE 设置开机自启动chkconfig --add zabbix_serverchkconfig zabbix_server on 启动zabbix_server1/etc/init.d/zabbix_server restart ElasticSearch 安装配置jdk 安装配置配置12345678910111213141516创建jdk文件夹mkdir -p /opt/aspire/product/jdk 解压jdk压缩包tar zxvf jdk-8u181-linux-x64.tar.gz -C /opt/aspire/product/jdk 编辑profile文件，添加jdk环境变量$ vi /etc/profile JAVA_HOME=//app/jdk/jdk1.8.0_181CLASSPATH=$JAVA_HOME/lib/PATH=$PATH:$JAVA_HOME/binexport PATH JAVA_HOME CLASSPATH 验证java环境，有输出正常$ java version 系统参数调整123456789101112131415编辑limit.conf配置文件$ vi /etc/security/limits.conf* soft nofile 65536* hard nofile 131072zabbix soft memlock unlimitedzabbix hard memlock unlimitedzabbix hard nproc 4096zabbix soft nproc 4096 内核参数优化$ vim /etc/sysctl.confvm.max_map_count=262144vm.swappiness=1 $ sysctl -p elasticsearch 6.1.4 安装配置12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970711.elesticsearch 6.1.4 下载省略 2.解压elasticsearchtar zxvf elesticsearch-6.1.4.tar.gz -C /opt/aspire/product/cd /opt/aspire/productmv elesticsearch-6.1.4 eleasticsearch6 3.创建data和logs文件夹mkdir -p eleasticsearch6/datamkdir -p eleasticsearch6/logs 4.授权目录权限chown -R zabbix.zabbix /opt/aspire/product/eleasticsearch6 5.修改配置文件$ vi /opt/aspire/product/zabbix/elasticsearch6/config/elasticsearch.yml #集群名称cluster.name: zabbix_elasticsearch#node节点的名称node.name: node-1 # 服务监听的ip地址network.host: 10.12.70.42# 是否可以成为主节点node.master: true# 该节点是否可以存储数据node.data: true# 节点属性node.attr.rack: r1# 设置索引数据的存储路径，多存储路径的话用逗号隔开path.data: /opt/aspire/product/zabbix/elasticsearch6/data# 日志存放路径path.logs: /opt/aspire/product/zabbix/elasticsearch6/logs# 锁定进程使用 的物理内存地址，避免使用swapbootstrap.memory_lock: true# 对外发布的ipnetwork.host: 0.0.0.0# 设置对外服务的http端口，默认为9200http.port: 9200# 节点交互使用的tcp端口transport.tcp.port: 9300# 设置集群中master节点的初始列表，可以通过这些节点来自动发现新加入集群的节点。discovery.zen.ping.unicast.hosts: [&quot;10.12.70.42&quot;]# 如果启用了 HTTP 端口，那么此属性会指定是否允许跨源 REST 请求http.cors.enabled: true# 如果 http.cors.enabled 的值为 true，那么该属性会指定允许 REST 请求来自何处。http.cors.allow-origin: &quot;*&quot; 6.以zabbix用户启动（不能使用root用户启动）su - zabbixcd /opt/aspire/product/elasticsearch6/bin./elasticsearch -d 7.验证安装情况,有如下输出则正常$ curl http://10.12.70.42:9200&#123; &quot;name&quot; : &quot;node-1&quot;, &quot;cluster_name&quot; : &quot;zabbix_elasticsearch&quot;, &quot;cluster_uuid&quot; : &quot;Aj_2YjcXRzSgaJLF0BQWjw&quot;, &quot;version&quot; : &#123; &quot;number&quot; : &quot;6.1.4&quot;, &quot;build_hash&quot; : &quot;d838f2d&quot;, &quot;build_date&quot; : &quot;2018-03-14T08:28:22.470Z&quot;, &quot;build_snapshot&quot; : false, &quot;lucene_version&quot; : &quot;7.1.0&quot;, &quot;minimum_wire_compatibility_version&quot; : &quot;5.6.0&quot;, &quot;minimum_index_compatibility_version&quot; : &quot;5.0.0&quot; &#125;, &quot;tagline&quot; : &quot;You Know, for Search&quot;&#125; elasticsearch-head插件安装可通过chrome浏览器插件和npm管理器两种方式安装 在chrome应用商店安装elasticsearch-head插件即可 通过npm管理器安装 1234567891011121314151617181920212223242526272829303132333435361.npm安装head插件 #创建相关目录mkdir /opt/aspire/product/elasticsearch-headcd /opt/aspire/product/elasticsearch-head #安装相关依赖yum -y install nodejs npmgit clone https://github.com/mobz/elasticsearch-head.gitnpm install grunt-clinpm install 2.修改配置文件 # 修改Gruntfile.js文件，修改监控地址，增加hostname属性$ vi Gruntfile.js connect: &#123; server: &#123; options: &#123; port: 9201, base: &apos;.&apos;, keepalive: true &#125; &#125; &#125; # 修改head/_site/app.js，修改head连接es的地址$ vi app.jsthis.base_uri = this.config.base_uri || this.prefs.get(&quot;app-base_uri&quot;) || &quot;http://localhost:9200&quot;; 3.后台启动cd /opt/aspire/product/elasticsearch-head/node_modules/grunt/binnohup ./grunt server &amp; exit启动成功后，可在浏览器访问插件与ES进行交互http://10.12.70.42:9201/ 界面展示如下 Kibana 安装配置Kibana下载省略 Kibana 安装配置12345678910111213141516171.创建kibana文件目录cd /opt/aspire/productmkdir kibana6 2.解压并授权tar zxvf kibana-6.1.4-linux-x86_64.tar.gz -C kibana6/chown -R zabbix.zabbix kibana6/ 3.修改配置文件$ vi kibana.yml# # kibana服务对外端口server.port: 5601# 本机ipserver.host: &quot;10.12.70.42&quot;# elasticsearch地址elasticsearch.url: &quot;http://10.12.70.42:9200&quot; web界面如下： Zabbix 同 ElasticSearch对接Elasticsearch支持以下几种监控项类型：uint,dbl,str,log,text支持的监控项类型通zabbix数据库说明如下： 监控项值类型 数据库表 Elasticsearch类型 Numeric(unsigned) history_uint uint Numeric(float) history dbl Character history_str str Log history_log log Text history_text text zabbix_server配置1234567891011121314151617181920211：修改zabbix_server.conf配置文件$ vi /opt/aspire/product/zabbix/etc/zabbix_server.conf HistoryStorageURL=http://10.12.70.42:9200HistoryStorageTypes=str,text,log,dbl,uint 2：修改zabbix.conf.php文件$ vi /opt/aspire/product/web/website/zabbix/conf/zabbix.conf.php (1):多台elasticsearch集群可按照如下方式配置$HISTORY[&apos;url&apos;] = [ &apos;uint&apos; =&gt; &apos;http://l.1.1.1:9200&apos;, &apos;text&apos; =&gt; &apos;http://2.2.2.2:9200&apos;];$HISTORY[&apos;types&apos;] = [&apos;uint&apos;, &apos;text&apos;]; (2):单台elsaticsearch汇总按照如下配置global $HISTORY;$DB;$HISTORY[&apos;url&apos;] = &apos;http://10.12.70.42:9203&apos;;// Value types stored in Elasticsearch.$HISTORY[&apos;types&apos;] = [&apos;str&apos;, &apos;text&apos;, &apos;log&apos;,&apos;dbl&apos;,&apos;uint&apos;]; 添加Elasticsearch mapping可在elasticsearch-head界面，kibana Dev tools界面操作，也可以使用curl命令操作 Kibana Dev tools界面： 12345PUT /uint &#123;json数据&#125;PUT /dbl &#123;json数据&#125;PUT /str &#123;json数据&#125;PUT /log &#123;json数据&#125;PUT /text &#123;json数据&#125; Curl 命令操作：12345curl -H &quot;Content-Type:application/json&quot; -XPUT http://10.12.70.42:9203/uint -d &apos; &#123;json数据&#125; &apos;curl -H &quot;Content-Type:application/json&quot; -XPUT http://10.12.70.42:9203/dbl -d &apos; &#123;json数据&#125; &apos;curl -H &quot;Content-Type:application/json&quot; -XPUT http://10.12.70.42:9203/str -d &apos; &#123;json数据&#125; &apos;curl -H &quot;Content-Type:application/json&quot; -XPUT http://10.12.70.42:9203/text -d &apos; &#123;json数据&#125; &apos;curl -H &quot;Content-Type:application/json&quot; -XPUT http://10.12.70.42:9203/log -d &apos; &#123;json数据&#125; &apos; json数据格式如下 1.添加uint_mapping123456789101112131415161718192021222324&#123; &quot;settings&quot; : &#123; &quot;index&quot; : &#123; &quot;number_of_replicas&quot; : 1, &quot;number_of_shards&quot; : 5 &#125; &#125;, &quot;mappings&quot; : &#123; &quot;values&quot; : &#123; &quot;properties&quot; : &#123; &quot;itemid&quot; : &#123; &quot;type&quot; : &quot;long&quot; &#125;, &quot;clock&quot; : &#123; &quot;format&quot; : &quot;epoch_second&quot;, &quot;type&quot; : &quot;date&quot; &#125;, &quot;value&quot; : &#123; &quot;type&quot; : &quot;long&quot; &#125; &#125; &#125; &#125;&#125; 2.添加dbl_mapping123456789101112131415161718192021222324&#123; &quot;settings&quot; : &#123; &quot;index&quot; : &#123; &quot;number_of_replicas&quot; : 1, &quot;number_of_shards&quot; : 5 &#125; &#125;, &quot;mappings&quot; : &#123; &quot;values&quot; : &#123; &quot;properties&quot; : &#123; &quot;itemid&quot; : &#123; &quot;type&quot; : &quot;long&quot; &#125;, &quot;clock&quot; : &#123; &quot;format&quot; : &quot;epoch_second&quot;, &quot;type&quot; : &quot;date&quot; &#125;, &quot;value&quot; : &#123; &quot;type&quot; : &quot;double&quot; &#125; &#125; &#125; &#125;&#125; 3.添加str_mapping1234567891011121314151617181920212223242526272829303132&#123; &quot;settings&quot; : &#123; &quot;index&quot; : &#123; &quot;number_of_replicas&quot; : 1, &quot;number_of_shards&quot; : 5 &#125; &#125;, &quot;mappings&quot; : &#123; &quot;values&quot; : &#123; &quot;properties&quot; : &#123; &quot;itemid&quot; : &#123; &quot;type&quot; : &quot;long&quot; &#125;, &quot;clock&quot; : &#123; &quot;format&quot; : &quot;epoch_second&quot;, &quot;type&quot; : &quot;date&quot; &#125;, &quot;value&quot; : &#123; &quot;fields&quot; : &#123; &quot;analyzed&quot; : &#123; &quot;index&quot; : true, &quot;type&quot; : &quot;text&quot;, &quot;analyzer&quot; : &quot;standard&quot; &#125; &#125;, &quot;index&quot; : false, &quot;type&quot; : &quot;text&quot; &#125; &#125; &#125; &#125;&#125; 4.添加text_mapping1234567891011121314151617181920212223242526272829303132&#123; &quot;settings&quot; : &#123; &quot;index&quot; : &#123; &quot;number_of_replicas&quot; : 1, &quot;number_of_shards&quot; : 5 &#125; &#125;, &quot;mappings&quot; : &#123; &quot;values&quot; : &#123; &quot;properties&quot; : &#123; &quot;itemid&quot; : &#123; &quot;type&quot; : &quot;long&quot; &#125;, &quot;clock&quot; : &#123; &quot;format&quot; : &quot;epoch_second&quot;, &quot;type&quot; : &quot;date&quot; &#125;, &quot;value&quot; : &#123; &quot;fields&quot; : &#123; &quot;analyzed&quot; : &#123; &quot;index&quot; : true, &quot;type&quot; : &quot;text&quot;, &quot;analyzer&quot; : &quot;standard&quot; &#125; &#125;, &quot;index&quot; : false, &quot;type&quot; : &quot;text&quot; &#125; &#125; &#125; &#125;&#125; 5.添加log_mapping1234567891011121314151617181920212223242526272829303132&#123; &quot;settings&quot; : &#123; &quot;index&quot; : &#123; &quot;number_of_replicas&quot; : 1, &quot;number_of_shards&quot; : 5 &#125; &#125;, &quot;mappings&quot; : &#123; &quot;values&quot; : &#123; &quot;properties&quot; : &#123; &quot;itemid&quot; : &#123; &quot;type&quot; : &quot;long&quot; &#125;, &quot;clock&quot; : &#123; &quot;format&quot; : &quot;epoch_second&quot;, &quot;type&quot; : &quot;date&quot; &#125;, &quot;value&quot; : &#123; &quot;fields&quot; : &#123; &quot;analyzed&quot; : &#123; &quot;index&quot; : true, &quot;type&quot; : &quot;text&quot;, &quot;analyzer&quot; : &quot;standard&quot; &#125; &#125;, &quot;index&quot; : false, &quot;type&quot; : &quot;text&quot; &#125; &#125; &#125; &#125;&#125; 添加后elasticsearch-head界面如下： Kibana关联elasticsearch创建索引正则 依次创建dbl,str,uint的index pattern即可 kibana过滤数据 假设查询str*下的数据，根据itemid value筛选数据如下 附录：X-pack安装在 Elasticsearch 中，配置认证是通过 X-Pack 插件实现的，kibana 版本高于6.3.2的已经自动集成了x-pack插件，低于该版本需要自行安装x-pack x-pack 安装123456789101112131415161718192021222324下载x-packwget https://artifacts.elastic.co/downloads/packs/x-pack/x-pack-6.2.2.zip 进入kibana/bin目录，安装kibana-plugin install x-pack-6.2.2.zip 修改kibana配置文件$ vi kibana.yml elasticsearch.username: &quot;kibana&quot;elasticsearch.password: &quot;CeoxAZHhQ17Hm9tyux33&quot;server.name: &quot;zdh-7&quot;server.host: &quot;10.43.159.7&quot;elasticsearch.url: &quot;http://10.43.159.7:9200&quot;xpack.monitoring.enabled: truexpack.security.enabled: truexpack.ml.enabled: truexpack.watcher.enabled: truexpack.graph.enabled: true 重启kibana进程$ ps -ef |grep node/bin/node |grep -v grep$ kill 9 pid$ /bin/kibana &amp;]]></content>
      <categories>
        <category>zabbix</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[VSftp配置及虚拟用户创建]]></title>
    <url>%2F2019%2F05%2F20%2Fvsftp%E9%85%8D%E7%BD%AE%E5%8F%8A%E8%99%9A%E6%8B%9F%E7%94%A8%E6%88%B7%E5%88%9B%E5%BB%BA.md%2F</url>
    <content type="text"><![CDATA[安装安装Vsftpd服务相关部件：[root@KcentOS5 ~]# yum install vsftpd* 确认安装PAM服务相关部件：[root@KcentOS5 ~]# yum install pam* 开发包，其实不装也没有关系，主要的目的是确认PAM。 1安装DB4部件包：这里要特别安装一个db4的包，用来支持文件数据库。[root@KcentOS5 ~]# yum install db4* 系统帐户建立Vsftpd服务的宿主用户：[root@KcentOS5 ~]# useradd vsftpd -s /sbin/nologin默认的Vsftpd的服务宿主用户是root，但是这不符合安全性的需要。这里建立名字为vsftpd的用户，用他来作为支持Vsftpd的服务宿主用户。由于该用户仅用来支持Vsftpd服务用，因此没有许可他登陆系统的必要，并设定他为不能登陆系统的用户。 建立Vsftpd虚拟宿主用户：`# useradd overlord -s /sbin/nologin 本篇主要是介绍Vsftp的虚拟用户，虚拟用户并不是系统用户，也就是说这些FTP的用户在系统中是不存在的。他们的总体权限其实是集中寄托在一个在系统中的某一个用户身上的，所谓Vsftpd的虚拟宿主用户，就是这样一个支持着所有虚拟用户的宿主用户。由于他支撑了FTP的所有虚拟的用户，那么他本身的权限将会影响着这些虚拟的用户，因此，处于安全性的考虑，也要非分注意对该用户的权限的控制，该用户也绝对没有登陆系统的必要，这里也设定他为不能登陆系统的用户。（这里插一句：原本在建立上面两个用户的时候，想连用户主路径也不打算给的。本来想加上 -d /home/nowhere 的，据man useradd手册上讲述：“ -d, –home HOME_DIRThe new user will be created using HOME_DIR as the value for theuser鈙 login directory. The default is to append the LOGIN name toBASE_DIR and use that as the login directory name. The directoryHOME_DIR does not have to exist but will not be created if it ismissing.使用-d参数指定用户的主目录，用户主目录并不是必须存在的。如果没有存在指定的目录的话，那么它将不会被建立”。 调整Vsftpd的配置文件：编辑配置文件前先备份[root@KcentOS5 ~]# cp /etc/vsftpd/vsftpd.conf /etc/vsftpd/vsftpd.conf.backup2.编辑主配置文件Vsftpd.conf[root@KcentOS5 ~]# vi /etc/vsftpd/vsftpd.conf这里我将原配置文件的修改完全记录，凡是修改的地方我都会保留注释原来的配置。其中加入我对每条配置项的认识，对于一些比较关键的配置项这里我做了我的观点，并且原本英语的说明我也不删除，供参考对比用。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142# Allow anonymous FTP? (Beware - allowed by default if you comment this out).#anonymous_enable=YESanonymous_enable=NO设定不允许匿名访问## Uncomment this to allow local users to log in.local_enable=YES设定本地用户可以访问。注意：主要是为虚拟宿主用户，如果该项目设定为NO那么所有虚拟用户将无法访问。## Uncomment this to enable any form of FTP write command.write_enable=YES设定可以进行写操作。## Default umask for local users is 077\. You may wish to change this to 022,# if your users expect that (022 is used by most other ftpd&apos;s)local_umask=022设定上传后文件的权限掩码。## Uncomment this to allow the anonymous FTP user to upload files. This only# has an effect if the above global write enable is activated. Also, you will# obviously need to create a directory writable by the FTP user.#anon_upload_enable=YESanon_upload_enable=NO禁止匿名用户上传。## Uncomment this if you want the anonymous FTP user to be able to create# new directories.#anon_mkdir_write_enable=YESanon_mkdir_write_enable=NO禁止匿名用户建立目录。## Activate directory messages - messages given to remote users when they# go into a certain directory.dirmessage_enable=YES设定开启目录标语功能。## Activate logging of uploads/downloads.xferlog_enable=YES设定开启日志记录功能。## Make sure PORT transfer connections originate from port 20 (ftp-data).connect_from_port_20=YES设定端口20进行数据连接。## If you want, you can arrange for uploaded anonymous files to be owned by# a different user. Note! Using &quot;root&quot; for uploaded files is not# recommended!#chown_uploads=YESchown_uploads=NO设定禁止上传文件更改宿主。#chown_username=whoever## You may override where the log file goes if you like. The default is shown# below.xferlog_file=/var/log/vsftpd.log设定Vsftpd的服务日志保存路径。注意，该文件默认不存在。必须要手动touch出来，并且由于这里更改了Vsftpd的服务宿主用户为手动建立的Vsftpd。必须注意给与该用户对日志的写入权限，否则服务将启动失败。## If you want, you can have your log file in standard ftpd xferlog formatxferlog_std_format=YES设定日志使用标准的记录格式。## You may change the default value for timing out an idle session.#idle_session_timeout=600设定空闲连接超时时间，这里使用默认。将具体数值留给每个具体用户具体指定，当然如果不指定的话，还是使用这里的默认值600，单位秒。## You may change the default value for timing out a data connection.#data_connection_timeout=120设定单次最大连续传输时间，这里使用默认。将具体数值留给每个具体用户具体指定，当然如果不指定的话，还是使用这里的默认值120，单位秒。## It is recommended that you define on your system a unique user which the# ftp server can use as a totally isolated and unprivileged user.#nopriv_user=ftpsecurenopriv_user=vsftpd设定支撑Vsftpd服务的宿主用户为手动建立的Vsftpd用户。注意，一旦做出更改宿主用户后，必须注意一起与该服务相关的读写文件的读写赋权问题。比如日志文件就必须给与该用户写入权限等。## Enable this and the server will recognise asynchronous ABOR requests. Not# recommended for security (the code is non-trivial). Not enabling it,# however, may confuse older FTP clients.async_abor_enable=YES设定支持异步传输功能。## By default the server will pretend to allow ASCII mode but in fact ignore# the request. Turn on the below options to have the server actually do ASCII# mangling on files when in ASCII mode.# Beware that on some FTP servers, ASCII support allows a denial of service# attack (DoS) via the command &quot;SIZE /big/file&quot; in ASCII mode. vsftpd# predicted this attack and has always been safe, reporting the size of the# raw file.# ASCII mangling is a horrible feature of the protocol.ascii_upload_enable=YESascii_download_enable=YES设定支持ASCII模式的上传和下载功能。## You may fully customise the login banner string:ftpd_banner=This Vsftp server supports virtual users ^_^设定Vsftpd的登陆标语。## You may specify a file of disallowed anonymous e-mail addresses. Apparently# useful for combatting certain DoS attacks.#deny_email_enable=YES# (default follows)#banned_email_file=/etc/vsftpd/banned_emails## You may specify an explicit list of local users to chroot() to their home# directory. If chroot_local_user is YES, then this list becomes a list of# users to NOT chroot().#chroot_list_enable=YESchroot_list_enable=NO禁止用户登出自己的FTP主目录。# (default follows)#chroot_list_file=/etc/vsftpd/chroot_list## You may activate the &quot;-R&quot; option to the builtin ls. This is disabled by# default to avoid remote users being able to cause excessive I/O on large# sites. However, some broken FTP clients such as &quot;ncftp&quot; and &quot;mirror&quot; assume# the presence of the &quot;-R&quot; option, so there is a strong case for enabling it.#ls_recurse_enable=YESls_recurse_enable=NO禁止用户登陆FTP后使用&quot;ls -R&quot;的命令。该命令会对服务器性能造成巨大开销。如果该项被允许，那么挡多用户同时使用该命令时将会对该服务器造成威胁。# When &quot;listen&quot; directive is enabled, vsftpd runs in standalone mode and# listens on IPv4 sockets. This directive cannot be used in conjunction# with the listen_ipv6 directive.listen=YES设定该Vsftpd服务工作在StandAlone模式下。顺便展开说明一下，所谓StandAlone模式就是该服务拥有自己的守护进程支持，在ps -A命令下我们将可用看到vsftpd的守护进程名。如果不想工作在StandAlone模式下，则可以选择SuperDaemon模式，在该模式下 vsftpd将没有自己的守护进程，而是由超级守护进程Xinetd全权代理，与此同时，Vsftp服务的许多功能将得不到实现。## This directive enables listening on IPv6 sockets. To listen on IPv4 and IPv6# sockets, you must run two copies of vsftpd whith two configuration files.# Make sure, that one of the listen options is commented !!#listen_ipv6=YESpam_service_name=vsftpd设定PAM服务下Vsftpd的验证配置文件名。因此，PAM验证将参考/etc/pam.d/下的vsftpd文件配置。userlist_enable=YES设定userlist_file中的用户将不得使用FTP。tcp_wrappers=YES设定支持TCP Wrappers。#KC: The following entries are added for supporting virtual ftp users.以下这些是关于Vsftpd虚拟用户支持的重要配置项目。默认Vsftpd.conf中不包含这些设定项目，需要自己手动添加配置。guest_enable=YES设定启用虚拟用户功能。guest_username=overlord指定虚拟用户的宿主用户。virtual_use_local_privs=YES设定虚拟用户的权限符合他们的宿主用户。user_config_dir=/etc/vsftpd/vconf设定虚拟用户个人Vsftp的配置文件存放路径。也就是说，这个被指定的目录里，将存放每个Vsftp虚拟用户个性的配置文件，一个需要注意的地方就是这些配置文件名必须和虚拟用户名相同。 保存退出。 建立Vsftpd的日志文件，并更该属主为Vsftpd的服务宿主用户：[root@KcentOS5 ~]# touch /var/log/vsftpd.log[root@KcentOS5 ~]# chown vsftpd.vsftpd /var/log/vsftpd.log 4.建立虚拟用户配置文件存放路径：[root@KcentOS5 ~]# mkdir /etc/vsftpd/vconf/ 制作虚拟用户数据库文件先建立虚拟用户名单文件：[root@KcentOS5 ~]# touch /etc/vsftpd/virtusers建立了一个虚拟用户名单文件，这个文件就是来记录vsftpd虚拟用户的用户名和口令的数据文件，我这里给它命名为virtusers。为了避免文件的混乱，我把这个名单文件就放置在/etc/vsftpd/下。 编辑虚拟用户名单文件：[root@KcentOS5 ~]# vi /etc/vsftpd/virtusers123456kanecruise123456near123456nearmello123456mello 编辑这个虚拟用户名单文件，在其中加入用户的用户名和口令信息。格式很简单：“一行用户名，一行口令”。 生成虚拟用户数据文件：[root@KcentOS5 ~]# db_load -T -t hash -f /etc/vsftpd/virtusers /etc/vsftpd/virtusers.db 察看db4的db_load命令使用方法：1234[root@KSRV2 vsftpd]# db_loadusage: db_load [-nTV] [-c name=value] [-f file][-h home] [-P password] [-t btree | hash | recno | queue] db_fileusage: db_load -r lsn | fileid [-h home] [-P password] db_file 察看生成的虚拟用户数据文件[root@KcentOS5 ~]# ll /etc/vsftpd/virtusers.db-rw-r–r– 1 root root 12288 Sep 16 03:51 /etc/vsftpd/virtusers.db需要特别注意的是，以后再要添加虚拟用户的时候，只需要按照“一行用户名，一行口令”的格式将新用户名和口令添加进虚拟用户名单文件。但是光这样做还不够，不会生效的哦！还要再执行一遍“ db_load -T -t hash -f 虚拟用户名单文件 虚拟用户数据库文件.db ”的命令使其生效才可以！ 设定PAM验证文件察看原来的Vsftp的PAM验证配置文件：1234567891011[root@KcentOS5 ~]# cat /etc/pam.d/vsftpd----------------------------------------------------------------#%PAM-1.0session optional pam_keyinit.so force revokeauth required pam_listfile.so item=user sense=deny file=/etc/vsftpd/ftpusers onerr=succeedauth required pam_shells.soauth include system-authaccount include system-authsession include system-authsession required pam_loginuid.so---------------------------------------------------------------- 在编辑前做好备份：123456[root@KcentOS5 ~]# cp /etc/pam.d/vsftpd /etc/pam.d/vsftpd.backup3.编辑Vsftpd的PAM验证配置文件[root@KcentOS5 ~]# vi /etc/pam.d/vsftpd----------------------------------------------------------------#%PAM-1.0auth sufficient /lib/security/pam_userdb.so db=/etc/vsftpd/virtusersaccount sufficient /lib/security/pam_userdb.so db=/etc/vsftpd/virtusers 以上两条是手动添加的，内容是对虚拟用户的安全和帐户权限进行验证。这里的auth是指对用户的用户名口令进行验证。这里的accout是指对用户的帐户有哪些权限哪些限制进行验证。其后的sufficient表示充分条件，也就是说，一旦在这里通过了验证，那么也就不用经过下面剩下的验证步骤了。相反，如果没有通过的话，也不会被系统立即挡之门外，因为sufficient的失败不决定整个验证的失败，意味着用户还必须将经历剩下来的验证审核。再后面的/lib/security/pam_userdb.so表示该条审核将调用pam_userdb.so这个库函数进行。最后的db=/etc/vsftpd/virtusers则指定了验证库函数将到这个指定的数据库中调用数据进行验证。 虚拟用户的配置规划好虚拟用户的主路径：[root@KcentOS5 ~]# mkdir /opt/vsftp/ 建立测试用户的FTP用户目录：[root@KcentOS5 ~]# mkdir /opt/vsftp/kanecruise/ /opt/vsftp/mello/ /opt/vsftp/near/ 建立虚拟用户配置文件模版：[root@KcentOS5 ~]# cp /etc/vsftpd/vsftpd.conf.backup /etc/vsftpd/vconf/vconf.tmp定制虚拟用户模版配置文件：[root@KcentOS5 ~]# vi /etc/vsftpd/vconf/vconf.tmp123456789101112131415161718192021222324--------------------------------local_root=/opt/vsftp/virtuser指定虚拟用户的具体主路径。anonymous_enable=NO设定不允许匿名用户访问。write_enable=YES设定允许写操作。local_umask=022设定上传文件权限掩码。anon_upload_enable=NO设定不允许匿名用户上传。anon_mkdir_write_enable=NO设定不允许匿名用户建立目录。idle_session_timeout=600设定空闲连接超时时间。data_connection_timeout=120设定单次连续传输最大时间。max_clients=10设定并发客户端访问个数。max_per_ip=5设定单个客户端的最大线程数，这个配置主要来照顾Flashget、迅雷等多线程下载软件。local_max_rate=50000设定该用户的最大传输速率，单位b/s。-------------------------------- 这里将原vsftpd.conf配置文件经过简化后保存作为虚拟用户配置文件的模版。这里将并不需要指定太多的配置内容，主要的框架和限制交由 Vsftpd的主配置文件vsftpd.conf来定义，即虚拟用户配置文件当中没有提到的配置项目将参考主配置文件中的设定。而在这里作为虚拟用户的配置文件模版只需要留一些和用户流量控制，访问方式控制的配置项目就可以了。这里的关键项是local_root这个配置，用来指定这个虚拟用户的FTP主路径。 更改虚拟用户的主目录的属主为虚拟宿主用户：123456[root@KcentOS5 ~]# chown -R overlord.overlord /opt/vsftp/6.检查权限：[root@KcentOS5 ~]# ll /opt/vsftp/total 24drwxr-xr-x 2 overlord overlord 4096 Sep 16 05:14 kanecruisedrwxr-xr-x 2 overlord overlord 4096 Sep 16 05:00 mellodrwxr-xr-x 2 overlord overlord 4096 Sep 16 05:00 near 给测试用户定制从虚拟用户模版配置文件复制：[root@KcentOS5 ~]# cp /etc/vsftpd/vconf/vconf.tmp /etc/vsftpd/vconf/kanecruise 针对具体用户进行定制：1234567891011121314[root@KcentOS5 ~]# vi /etc/vsftpd/vconf/kanecruise---------------------------------local_root=/opt/vsftp/kanecruiseanonymous_enable=NOwrite_enable=YESlocal_umask=022anon_upload_enable=NOanon_mkdir_write_enable=NOidle_session_timeout=300data_connection_timeout=90max_clients=1max_per_ip=1local_max_rate=25000--------------------------------- 启动服务12[root@KcentOS5 ~]# service vsftpd startStarting vsftpd for vsftpd: [ OK ] 测试在虚拟用户目录中预先放入文件：1[root@KcentOS5 ~]# touch /opt/vsftp/kanecruise/kc.test 从其他机器作为客户端登陆FTP：12345678910111213[root@Yum ~]# ftpftp&gt; open 192.168.1.22Connected to 192.168.1.22.220 This Vsftp server supports virtual users ^_^530 Please login with USER and PASS.530 Please login with USER and PASS.KERBEROS_V4 rejected as an authentication typeName (192.168.1.22:root): kanecruise331 Please specify the password.Password: 123456230 Login successful.Remote system type is UNIX.Using binary mode to transfer files. 测试列单操作12345ftp&gt; ls227 Entering Passive Mode (192,168,1,22,220,24)150 Here comes the directory listing.-rw-r--r-- 1 501 501 0 Sep 15 21:14 kc.test226 Directory send OK.（目录列单成功） 测试上传操作：123456789ftp&gt; put(local-file) KC.repo(remote-file) KC.repolocal: KC.repo remote: KC.repo227 Entering Passive Mode (192,168,1,22,230,1)150 Ok to send data.226 File receive OK. （上传成功）699 bytes sent in 0.024 seconds (29 Kbytes/s)ftp&gt; 测试建立目录操作：12ftp&gt; mkdir test257 &quot;/opt/vsftp/kanecruise/test&quot; created （目录建立成功） 测试下载操作：12345ftp&gt; get kc.testlocal: kc.test remote: kc.test227 Entering Passive Mode (192,168,1,22,164,178)150 Opening BINARY mode data connection for kc.test (0 bytes).226 File send OK.（下载成功） 测试超时：1234567891011121314151617181920212223ftp&gt; dir421 Timeout.（超时有效）ftp&gt; userNot connected.注意:在/etc/vsftpd/vsftpd.conf中，local_enable的选项必须打开为Yes，使得虚拟用户的访问成为可能，否则会出现以下现象：----------------------------------[root@KcentOS5 ~]# ftpftp&gt; open 192.168.1.22Connected to 192.168.1.22.500 OOPS: vsftpd: both local and anonymous access disabled!----------------------------------原因：虚拟用户再丰富，其实也是基于它们的宿主用户overlord的，如果overlord这个虚拟用户的宿主被限制住了，那么虚拟用户也将受到限制。**补充：**500 OOPS:错误有可能是你的vsftpd.con配置文件中有不能被实别的命令，还有一种可能是命令的YES 或 NO 后面有空格。我遇到的是命令后面有空格。因为我是用GEDIT来编辑的配置文件550 权限错误,不能创建目录和文件**解决方法: 关闭selinux**# vi /etc/selinux/config将 SELINUX=XXX --&gt;XXX 代表级别,改为SELINUX=disabled重启]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>vsftp</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux配置网络]]></title>
    <url>%2F2018%2F08%2F27%2FLinux%20%E9%85%8D%E7%BD%AE%E7%BD%91%E7%BB%9C%2F</url>
    <content type="text"><![CDATA[第一种：环境：centos 7/虚拟机NAT模式 （1）：设置静态ip上网 编辑网卡文件 1234567891011# vim /etc/sysconfig/network-scripts/ifcfg-ens32TYPE=&quot;Ethernet&quot; BOOTPROTO=&quot;static&quot; #静态获取ipIPADDR=192.168.78.135 #手动设置ipNETMASK=255.255.255.0 #子网掩码GATEWAY=192.168.78.2 #网关NAME=&quot;ens32&quot;DEVICE=&quot;ens32&quot; #网卡名ONBOOT=&quot;yes&quot; #默认启动DNS=114.114.114.114 #域名解析 2：编辑resolv.conf文件 12345# vim /etc/resolv.confsearch localdomainnameserver 192.168.78.2nameserver 114.114.114.114 3：重新启动网络服务 1# systemctl restart network （2）设置DHCP上网12345678# vim /etc/sysconfig/network-scripts/ifcfg-ens32TYPE=&quot;Ethernet&quot; BOOTPROTO=&quot;dhcp&quot; #静态获取ipNAME=&quot;ens32&quot;DEVICE=&quot;ens32&quot; #网卡名ONBOOT=&quot;yes&quot; #默认启动DNS=114.114.114.114 #域名解析 2：重新启动网络服务 1# systemctl restart network]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux分区方案]]></title>
    <url>%2F2018%2F08%2F27%2FLinux%E5%88%86%E5%8C%BA%E6%96%B9%E6%A1%88%E4%B8%8E%E8%BF%87%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[Linux分区方案：方案1：（监控服务器，负载均衡器）12345678910111./boot引导分区，存放引导文件和Linux内核。 启动文件：用于判断你需要启动哪个操作系统或启动哪个内核。 内核：简单的讲，程序与硬件间的桥梁，你使用应用程序通过内核控制整个计算机。 分区时一般设定：100-200M.2.swapSwap分区，作为虚拟内存使用。在系统的物理内存不够用的时候，把硬盘空间中的一部分空间释放出来，以供当前运行的程序使用。分区时一般设定：内存大小的1到1.5倍.3./作为文件系统的根目录剩余的给根分区。 方案2：（适合数据库服务器，存储服务器，共享存储服务器NFS）123456789101112131./boot引导分区，存放引导文件和Linux内核。 启动文件：用于判断你需要启动哪个操作系统或启动哪个内核。 内核：简单的讲，程序与硬件间的桥梁，你使用应用程序通过内核控制整个计算机。 分区时一般设定：100-200M.2.swapSwap分区，作为虚拟内存使用。在系统的物理内存不够用的时候，把硬盘空间中的一部分空间释放出来，以供当前运行的程序使用。分区时一般设定：内存大小的1到1.5倍.3./作为文件系统的根目录剩余的给根分区。4./data剩余的全部给data分区，用与存放重要数据。 方案3：（适合大门户网站的服务器）1234567891011121./boot引导分区，存放引导文件和Linux内核。 启动文件：用于判断你需要启动哪个操作系统或启动哪个内核。 内核：简单的讲，程序与硬件间的桥梁，你使用应用程序通过内核控制整个计算机。 分区时一般设定：100-200M.2.swapSwap分区，作为虚拟内存使用。在系统的物理内存不够用的时候，把硬盘空间中的一部分空间释放出来，以供当前运行的程序使用。分区时一般设定：内存大小的1到1.5倍.3./作为文件系统的根目录剩余的给根分区。4.剩余的磁盘不分区，哪里有需要再分给谁。 分区过程：1：图形化分区123456781）：勾选我要配置分区[http://img.blog.csdn.net/20150530112939843?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvbGl1eWFubGluZ2xhbnE=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center](https://note.youdao.com/)2）：点击完成，到手动分区界面；做2步，先将分区方案改为标准分区，然后点击“点这里自动创建他们（C）”按钮。 [http://img.blog.csdn.net/20150530112923166?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvbGl1eWFubGluZ2xhbnE=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center](https://note.youdao.com/)3）：到另一个手动分区界面。然后点击左下角的+号，添加/home，/boot,/var和swap，以及/目录。根据分配给磁盘最大大小，合理设置他们的大小，其中/home,/boot,/var和swap都明确的指定大小，而/不指定大小，则剩余的都是他的，所以最后一个配置/[http://img.blog.csdn.net/20150530112856100?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvbGl1eWFubGluZ2xhbnE=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center](https://note.youdao.com/) 2：命令行分区具体参考：https://www.cnblogs.com/leefan/p/5445542.html]]></content>
      <categories>
        <category>Mysql</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql相关命令]]></title>
    <url>%2F2018%2F08%2F26%2F%E6%95%B0%E6%8D%AE%E5%BA%93%E7%9B%B8%E5%85%B3%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[1：设置数据库密码第一种方法：mysql -uroot -p 进入数据库后 mysql&gt;set password=password(“新密码”); mysql&gt;flush privileges; 第二种方法：使用GRANT语句 mysql&gt;grant all on . to ‘root’@’localhost’ IDENTIFIED BY ‘你的密码’with grant option ; mysql&gt;flush privileges; 第三种方法：mysqladmin mysqladmin命令格式：mysqladmin -u 用户名 -p 旧密码 password 新密码 mysqladmin -u root -p “old passwd” password “new passwd”]]></content>
      <categories>
        <category>Mysql</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[DNS域名解析服务]]></title>
    <url>%2F2017%2F12%2F24%2Fdnsjiexi%2F</url>
    <content type="text"><![CDATA[&emsp;想起秋招时的一个笔试题，DNS域名解析服务的原理，老实讲当时没有答正确，而是回答的是输入域名到访问网站的过程，第二天面试的时候还问我怎么错了实属尴尬，不过结果还挺幸运。 DNS域名解析服务采用分布式数据结构来存放数据，在执行用户发起的域名查询请求时，具有递归查询和迭代查询两种方式。 递归查询：域名服务器将代替提出请求的客户机(下级DNS服务器)进行域名查询，若域名服务器不能直接回答，则域名服务器会在域各树中的各分支的上下进行递归查询，最终将返回查询结果给客户机，在域名服务器查询期间，客户机将完全处于等待状态。 迭代查询：域名服务器将代替提出请求的客户机(下级DNS服务器)进行域名查询，若域名服务器不能直接回答，则域名服务器会在域各树中的各分支的上下进行递归查询，最终将返回查询结果给客户机，在域名服务器查询期间，客户机将完全处于等待状态。 DNS域名称空间的组织方式&emsp;按其功能命名空间中用来描述 DNS 域名称的五个类别的介绍详见下表中，以及与每个名称类型的示例。 DNS服务的工作过程当 DNS 客户机需要查询程序中使用的名称时，它会查询本地DNS 服务器来解析该名称。客户机发送的每条查询消息都包括3条信息，以指定服务器应回答的问题。 ● 指定的 DNS 域名，表示为完全合格的域名 (FQDN) 。● 指定的查询类型，它可根据类型指定资源记录，或作为查询操作的专门类型。● DNS域名的指定类别。 DNS 查询的过程如下图所示： 1、在浏览器中输入www.qq.com域名，操作系统会先检查自己本地的hosts文件是否有这个网址映射关系，如果有，就先调用这个IP地址映射，完成域名解析。 2、如果hosts里没有这个域名的映射，则查找本地DNS解析器缓存，是否有这个网址映射关系，如果有，直接返回，完成域名解析。 3、如果hosts与本地DNS解析器缓存都没有相应的网址映射关系，首先会找TCP/ip参数中设置的首选DNS服务器，在此我们叫它本地DNS服务器，此服务器收到查询时，如果要查询的域名，包含在本地配置区域资源中，则返回解析结果给客户机，完成域名解析，此解析具有权威性。 4、如果要查询的域名，不由本地DNS服务器区域解析，但该服务器已缓存了此网址映射关系，则调用这个IP地址映射，完成域名解析，此解析不具有权威性。 5、如果本地DNS服务器本地区域文件与缓存解析都失效，则根据本地DNS服务器的设置（是否设置转发器）进行查询，如果未用转发模式，本地DNS就把请求发至13台根DNS，根DNS服务器收到请求后会判断这个域名(.com)是谁来授权管理，并会返回一个负责该顶级域名服务器的一个IP。本地DNS服务器收到IP信息后，将会联系负责.com域的这台服务器。这台负责.com域的服务器收到请求后，如果自己无法解析，它就会找一个管理.com域的下一级DNS服务器地址(qq.com)给本地DNS服务器。当本地DNS服务器收到这个地址后，就会找qq.com域服务器，重复上面的动作，进行查询，直至找到www.qq.com主机。 6、如果用的是转发模式，此DNS服务器就会把请求转发至上一级DNS服务器，由上一级服务器进行解析，上一级服务器如果不能解析，或找根DNS或把转请求转至上上级，以此循环。不管是本地DNS服务器用是是转发，还是根提示，最后都是把结果返回给本地DNS服务器，由此DNS服务器再返回给客户机。 附：从输入域名到访问网站的网络过程]]></content>
      <categories>
        <category>网络</category>
      </categories>
      <tags>
        <tag>DNS</tag>
        <tag>域名解析</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[firewall-cmd的使用]]></title>
    <url>%2F2017%2F12%2F23%2Ffirewall-cmd-use%2F</url>
    <content type="text"><![CDATA[firewall有几个分区(zone):drop：任何流入网络的包都被丢弃，不作出任何响应。只允许流出的网络连接。block：任何进入的网络连接都被拒绝，并返回 IPv4 的 icmp-host-prohibited 报文或者 IPv6 的 icmp6-adm-prohibited 报文。只允许由该系统初始化的网络连接。public：用以可以公开的部分。你认为网络中其他的计算机不可信并且可能伤害你的计算机。只允许选中的连接接入。external：用在路由器等启用伪装的外部网络。你认为网络中其他的计算机不可信并且可能伤害你的计算机。只允许选中的连接接入。dmz：用以允许隔离区（dmz）中的电脑有限地被外界网络访问。只接受被选中的连接。work：用在工作网络。你信任网络中的大多数计算机不会影响你的计算机。只接受被选中的连接。home：用在家庭网络。你信任网络中的大多数计算机不会影响你的计算机。只接受被选中的连接。internal：用在内部网络。你信任网络中的大多数计算机不会影响你的计算机。只接受被选中的连接。 然后就是简单地使用方法：要使定义的协议永久生效，需要加一句 –permanent，–zone不写则使用默认区域设置默认区域： firewall-cmd –set-default-zone=public 查询默认区域： firewall-cmd –get-default-zone 添加指定端口： firewall-cmd --zone=&lt;zone&gt; --add-port=&lt;port&gt;[-&lt;port&gt;]/&lt;protocol&gt; [--timeout=&lt;seconds&gt;] 允许外部连接接入，端口1234，TCP协议： firewall-cmd –zone=public –add-port=1234/tcp 移除允许的端口： firewall-cmd [–zone=] –remove-port=[-]/ 查询端口是否启用： firewall-cmd [–zone=] –query-port=[-]/ 启用一项服务： firewall-cmd –permanent [–zone=] –add-service= 禁用一项服务： firewall-cmd --permanent [--zone=&lt;zone&gt;] --remove-service=&lt;service&gt; 查询一项服务是否启用： firewall-cmd –permanent [–zone=] –query-service= 重新加载防火墙规则：不用重启服务: firewall-cmd –reload 会重启服务： firewall-cmd --complete-reload 如果还不行，可以用用: service firewalld restart 这么多差不多能简单的设置一下firewall，具体可以看：https://fedoraproject.org/wiki/FirewallD/zh-cn]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>firewall</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[那是什么样的日子]]></title>
    <url>%2F2017%2F11%2F21%2Fthat_day%2F</url>
    <content type="text"><![CDATA[纪念waney blog诞生的日子。 完全不懂markdown语法，所以排版很混乱，见谅，也算是完成了大四以来甚至的大三的一个小目标，不管用什么方法，抛开CSDN和博客园搭建一个自己的博客网站，讲道理，托管在github上，速度还是比较蜗牛的，过段时间拖到码云（oschina）上去，应该会稍微好点吧，然后在过多久（自己也不知道需要多久），自己买个服务器自己搭建起来，好像快看到用LAMP搭建服务器了，应该差不过吧。大四了，还有半个学期，过得也是真的块，没啥说的，好好学习，好好减肥，然后找个媳妇。en,就这样]]></content>
      <categories>
        <category>个人</category>
      </categories>
      <tags>
        <tag>personal</tag>
      </tags>
  </entry>
</search>
